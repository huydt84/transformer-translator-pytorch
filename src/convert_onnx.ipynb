{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dinh.trong.huy/nmt-data-envija/transformer-translator-pytorch\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "import sentencepiece\n",
    "import torch\n",
    "from constants import *\n",
    "from custom_data import *\n",
    "from transformer import *\n",
    "from data_structure import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Transformer(64000, 64000)\n",
    "# checkpoint = torch.load(\"saved_model\\\\best_ckpt.tar\", map_location=torch.device('cpu'))\n",
    "model.load_state_dict(torch.load(\"saved_model/ckpt1.pt\", map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_sp = spm.SentencePieceProcessor()\n",
    "trg_sp = spm.SentencePieceProcessor()\n",
    "src_sp.load(f\"{SP_DIR}/{src_model_prefix}.model\")\n",
    "trg_sp.load(f\"{SP_DIR}/{trg_model_prefix}.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = \"Hello my friend\"\n",
    "tokenized = src_sp.EncodeAsIds(input_sentence)\n",
    "src = torch.LongTensor(pad_or_truncate(tokenized)).unsqueeze(0).to(device) # (1, L)\n",
    "e_mask = (src != pad_id).unsqueeze(1).to(device) # (1, 1, L)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 256, 512)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_embedding_part(model, src, save_path): \n",
    "    print(src.shape)\n",
    "    src_data = model.src_embedding(src) \n",
    "    torch.onnx.export(model.src_embedding, \n",
    "                      src, \n",
    "                      save_path, \n",
    "                      export_params=True, \n",
    "                      opset_version=16, \n",
    "                      do_constant_folding=True, \n",
    "                      input_names=['src'], \n",
    "                      output_names=['src_data']) \n",
    "    return src_data.detach().numpy().shape\n",
    "\n",
    "src_data = convert_embedding_part(model, src, \"onnx_test\\\\src_embedding.onnx\")\n",
    "src_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Diagnostic Run torch.onnx.export version 2.0.0+cpu ==============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def convert_pe_part(model, src, save_path): \n",
    "    src_data2 = model.positional_encoder(src) \n",
    "    torch.onnx.export(model.positional_encoder, \n",
    "                      src, \n",
    "                      save_path, \n",
    "                      export_params=True, \n",
    "                      opset_version=16, \n",
    "                      do_constant_folding=True, \n",
    "                      input_names=['src_data'], \n",
    "                      output_names=['src_data2']) \n",
    "    return src_data2\n",
    "\n",
    "src_data2 = convert_pe_part(model, src_data, \"onnx_test\\\\positional_encoder.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Diagnostic Run torch.onnx.export version 2.0.0+cpu ==============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def convert_encoder_part(model, src, src_mask, save_path): \n",
    "    e_output = model.encoder(src, src_mask) \n",
    "    torch.onnx.export(model.encoder, \n",
    "                      (src, src_mask), \n",
    "                      save_path, \n",
    "                      export_params=True, \n",
    "                      opset_version=16, \n",
    "                      do_constant_folding=True, \n",
    "                      input_names=['src_data2', 'e_mask'], \n",
    "                      output_names=['e_output']) \n",
    "    return e_output\n",
    "\n",
    "e_output = convert_encoder_part(model, src_data2, e_mask, \"onnx_test\\\\encoder.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Diagnostic Run torch.onnx.export version 2.0.0+cpu ==============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "last_words = torch.LongTensor([pad_id] * seq_len) # (L)\n",
    "last_words[0] = sos_id # (L)\n",
    "cur_len = 1\n",
    "\n",
    "trg = last_words.unsqueeze(0)\n",
    "        \n",
    "d_mask = (last_words.unsqueeze(0) != pad_id).unsqueeze(1) # (1, 1, L)\n",
    "nopeak_mask = torch.ones([1, seq_len, seq_len], dtype=torch.bool)  # (1, L, L)\n",
    "nopeak_mask = torch.tril(nopeak_mask)  # (1, L, L) to triangular shape\n",
    "d_mask = d_mask & nopeak_mask\n",
    "\n",
    "def convert_embedding2_part(model, trg, save_path): \n",
    "    trg_embedded = model.trg_embedding(trg) \n",
    "    torch.onnx.export(model.trg_embedding, \n",
    "                      trg, \n",
    "                      save_path, \n",
    "                      export_params=True, \n",
    "                      opset_version=16, \n",
    "                      do_constant_folding=True, \n",
    "                      input_names=['trg'], \n",
    "                      output_names=['trg_embedded']) \n",
    "    return trg_embedded\n",
    "\n",
    "trg_embedded = convert_embedding2_part(model, trg, \"onnx_test\\\\trg_embedding.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trg_positional_encoded = model.positional_encoder(trg_embedded) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Diagnostic Run torch.onnx.export version 2.0.0+cpu ==============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def convert_decoder_part(model, trg_positional_encoded, e_output, e_mask, d_mask, save_path): \n",
    "    decoder_output = model.decoder(\n",
    "                trg_positional_encoded,\n",
    "                e_output,\n",
    "                e_mask,\n",
    "                d_mask\n",
    "            ) # (1, L, d_model) \n",
    "    torch.onnx.export(model.decoder, \n",
    "                      (trg_positional_encoded, e_output, e_mask, d_mask), \n",
    "                      save_path, \n",
    "                      export_params=True, \n",
    "                      opset_version=16, \n",
    "                      do_constant_folding=True, \n",
    "                      input_names=['trg_positional_encoded', 'e_output', 'e_mask', 'd_mask'], \n",
    "                      output_names=['decoder_output']) \n",
    "    return decoder_output\n",
    "\n",
    "decoder_output = convert_decoder_part(model, trg_positional_encoded, e_output, e_mask, d_mask, \"onnx_test\\\\decoder.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def convert_linear_part(model, d_output, save_path): \n",
    "    l_output = model.output_linear(d_output) \n",
    "    torch.onnx.export(model.positional_encoder, \n",
    "                      d_output, \n",
    "                      save_path, \n",
    "                      export_params=True, \n",
    "                      opset_version=16, \n",
    "                      do_constant_folding=True, \n",
    "                      input_names=['d_output'], \n",
    "                      output_names=['l_output']) \n",
    "    return l_output\n",
    "\n",
    "d_output = torch.randn(1, seq_len, d_model).to(\"cpu\")\n",
    "l_output = convert_linear_part(model, d_output, \"onnx_test/output_linear.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogSoftmax(dim=-1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def convert_softmax_part(model, l_output, save_path): \n",
    "    output = model.softmax(l_output) \n",
    "    torch.onnx.export(model.softmax, \n",
    "                      l_output, \n",
    "                      save_path, \n",
    "                      export_params=True, \n",
    "                      opset_version=16, \n",
    "                      do_constant_folding=True, \n",
    "                      input_names=['l_output'], \n",
    "                      output_names=['output']) \n",
    "    return output\n",
    "\n",
    "\n",
    "output = convert_softmax_part(model, l_output, \"onnx_test/softmax.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and check model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import os\n",
    "\n",
    "embed1 = onnx.load(os.path.join(ONNX_DIR, \"src_embedding.onnx\"))\n",
    "embed2 = onnx.load(os.path.join(ONNX_DIR, \"trg_embedding.onnx\"))\n",
    "pe = onnx.load(os.path.join(ONNX_DIR, \"positional_encoder.onnx\"))\n",
    "encoder = onnx.load(os.path.join(ONNX_DIR, \"encoder.onnx\"))\n",
    "decoder = onnx.load(os.path.join(ONNX_DIR, \"decoder.onnx\"))\n",
    "linear = onnx.load(os.path.join(ONNX_DIR, \"output_linear.onnx\"))\n",
    "softmax = onnx.load(os.path.join(ONNX_DIR, \"softmax.onnx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx.checker.check_model(embed1)\n",
    "onnx.checker.check_model(embed2)\n",
    "onnx.checker.check_model(pe)\n",
    "onnx.checker.check_model(encoder)\n",
    "onnx.checker.check_model(decoder)\n",
    "onnx.checker.check_model(linear)\n",
    "onnx.checker.check_model(softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx.helper.printable_graph(encoder.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "\n",
    "src_embed = onnxruntime.InferenceSession(os.path.join(ONNX_DIR, \"src_embedding.onnx\"))\n",
    "trg_embed = onnxruntime.InferenceSession(os.path.join(ONNX_DIR, \"trg_embedding.onnx\"))\n",
    "pe = onnxruntime.InferenceSession(os.path.join(ONNX_DIR, \"positional_encoder.onnx\"))\n",
    "encoder = onnxruntime.InferenceSession(os.path.join(ONNX_DIR, \"encoder.onnx\"))\n",
    "decoder = onnxruntime.InferenceSession(os.path.join(ONNX_DIR, \"decoder.onnx\"))\n",
    "linear = onnxruntime.InferenceSession(os.path.join(ONNX_DIR, \"output_linear.onnx\"))\n",
    "softmax = onnxruntime.InferenceSession(os.path.join(ONNX_DIR, \"softmax.onnx\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "class Translator():\n",
    "    def __init__(self, session) -> None:\n",
    "        self.src_embed, self.trg_embed, self.pe, self.encoder, self.decoder, self.linear, self.softmax = session\n",
    "        self.src_sp = spm.SentencePieceProcessor()\n",
    "        self.trg_sp = spm.SentencePieceProcessor()\n",
    "        self.src_sp.load(f\"{SP_DIR}/{src_model_prefix}.model\")\n",
    "        self.trg_sp.load(f\"{SP_DIR}/{trg_model_prefix}.model\")\n",
    "        \n",
    "\n",
    "    def translate(self, input_sentence, method=\"greedy\"):\n",
    "        tokenized = self.src_sp.EncodeAsIds(input_sentence)\n",
    "        src = np.expand_dims(pad_or_truncate(tokenized), axis=0).astype('int64') # (1, L)\n",
    "        e_mask = np.expand_dims((src != pad_id), axis=1) # (1, 1, L)\n",
    "        print(src.shape)\n",
    "        \n",
    "        src_embed_input = { self.src_embed.get_inputs()[0].name: src }\n",
    "        src_embed = self.src_embed.run(None, src_embed_input)[0]\n",
    "        print(np.array(src_embed).shape)\n",
    "        \n",
    "        src_pe_input = { self.pe.get_inputs()[0].name: src_embed }\n",
    "        src_pe = self.pe.run(None, src_pe_input)[0]\n",
    "        print(np.array(src_pe).shape)\n",
    "        \n",
    "        e_output_input = { self.encoder.get_inputs()[0].name: src_pe, self.encoder.get_inputs()[1].name: e_mask}\n",
    "        e_output = self.encoder.run(None, e_output_input)[0]\n",
    "        print(np.array(e_output).shape)\n",
    "        \n",
    "        if method == 'greedy':\n",
    "            print(\"Greedy decoding selected.\")\n",
    "            result = self.greedy_search(e_output, e_mask, trg_sp)\n",
    "\n",
    "        return result\n",
    "        \n",
    "    def greedy_search(self, e_output, e_mask, trg_sp):\n",
    "        last_words = [pad_id] * seq_len\n",
    "        last_words[0] = sos_id\n",
    "        cur_len = 1\n",
    "\n",
    "        for i in range(seq_len):\n",
    "            lw_expand = np.expand_dims(last_words, axis=0)\n",
    "            d_mask = np.expand_dims((lw_expand != pad_id), axis=1) # (1, 1, L)\n",
    "            nopeak_mask = np.ones((1, seq_len, seq_len)).astype('bool')\n",
    "            nopeak_mask = np.tril(nopeak_mask) # (1, L, L) to triangular shape\n",
    "            d_mask = d_mask & nopeak_mask # (1, L, L) padding false\n",
    "\n",
    "            trg_embed_input = { self.trg_embed.get_inputs()[0].name: lw_expand}\n",
    "            trg_embed = self.trg_embed.run(None, trg_embed_input)[0]\n",
    "\n",
    "            trg_pe_input = { self.pe.get_inputs()[0].name: trg_embed }\n",
    "            trg_pe = self.pe.run(None, trg_pe_input)[0]\n",
    "\n",
    "            decoder_input = {self.decoder.get_inputs()[0].name: trg_pe,\n",
    "                                    self.decoder.get_inputs()[1].name: e_output,\n",
    "                                    self.decoder.get_inputs()[2].name: e_mask,\n",
    "                                    self.decoder.get_inputs()[3].name: d_mask}\n",
    "            decoder_output = self.decoder.run(None, decoder_input)[0]\n",
    "\n",
    "            linear_input = { self.linear.get_inputs()[0].name: decoder_output}\n",
    "            linear_output = self.linear.run(None, linear_input)[0]\n",
    "\n",
    "            softmax_input = { self.linear.get_inputs()[0].name: linear_output}\n",
    "            softmax_output = self.linear.run(None, softmax_input)[0]\n",
    "\n",
    "            output = np.argmax(softmax_output, axis=-1)\n",
    "            last_word_id = output[0][i].item()\n",
    "\n",
    "            if i < seq_len-1:\n",
    "                last_words[i+1] = last_word_id\n",
    "                cur_len += 1\n",
    "            \n",
    "            if last_word_id == eos_id:\n",
    "                break\n",
    "\n",
    "        if last_words[-1] == pad_id:\n",
    "            decoded_output = last_words[1:cur_len]\n",
    "        else:\n",
    "            decoded_output = last_words[1:]\n",
    "        decoded_output = trg_sp.decode_ids(decoded_output)\n",
    "        \n",
    "        return decoded_output\n",
    "\n",
    "    def beam_search(self, e_output, e_mask, trg_sp):\n",
    "        cur_queue = PriorityQueue()\n",
    "        for k in range(beam_size):\n",
    "            cur_queue.put(BeamNode(sos_id, -0.0, [sos_id]))\n",
    "        \n",
    "        finished_count = 0\n",
    "        \n",
    "        for pos in range(seq_len):\n",
    "            new_queue = PriorityQueue()\n",
    "            for k in range(beam_size):\n",
    "                node = cur_queue.get()\n",
    "                if node.is_finished:\n",
    "                    new_queue.put(node)\n",
    "                else:\n",
    "                    trg_input = torch.LongTensor(node.decoded + [pad_id] * (seq_len - len(node.decoded))).to(device) # (L)\n",
    "                    d_mask = (trg_input.unsqueeze(0) != pad_id).unsqueeze(1).to(device) # (1, 1, L)\n",
    "                    nopeak_mask = torch.ones([1, seq_len, seq_len], dtype=torch.bool).to(device)\n",
    "                    nopeak_mask = torch.tril(nopeak_mask) # (1, L, L) to triangular shape\n",
    "                    d_mask = d_mask & nopeak_mask # (1, L, L) padding false\n",
    "                    \n",
    "                    output = self.model.decoder(\n",
    "                        trg_input.unsqueeze(0),\n",
    "                        e_output,\n",
    "                        e_mask,\n",
    "                        d_mask\n",
    "                    ) # (1, L, trg_vocab_size)\n",
    "                    \n",
    "                    output = torch.topk(output[0][pos], dim=-1, k=beam_size)\n",
    "                    last_word_ids = output.indices.tolist() # (k)\n",
    "                    last_word_prob = output.values.tolist() # (k)\n",
    "                    \n",
    "                    for i, idx in enumerate(last_word_ids):\n",
    "                        new_node = BeamNode(idx, -(-node.prob + last_word_prob[i]), node.decoded + [idx])\n",
    "                        if idx == eos_id:\n",
    "                            new_node.prob = new_node.prob / float(len(new_node.decoded))\n",
    "                            new_node.is_finished = True\n",
    "                            finished_count += 1\n",
    "                        new_queue.put(new_node)\n",
    "            \n",
    "            cur_queue = copy.deepcopy(new_queue)\n",
    "            \n",
    "            if finished_count == beam_size:\n",
    "                break\n",
    "        \n",
    "        decoded_output = cur_queue.get().decoded\n",
    "        \n",
    "        if decoded_output[-1] == eos_id:\n",
    "            decoded_output = decoded_output[1:-1]\n",
    "        else:\n",
    "            decoded_output = decoded_output[1:]\n",
    "            \n",
    "        return trg_sp.decode_ids(decoded_output)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256)\n",
      "(1, 256, 512)\n",
      "(1, 256, 512)\n",
      "(1, 256, 512)\n",
      "Greedy decoding selected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'nóiợp nóiợp nóiợp nói nóiợp nóiợp nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói nói'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session = (src_embed, trg_embed, pe, encoder, decoder, linear, softmax)\n",
    "translator = Translator(session)\n",
    "translator.translate(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_onnx(img, session, max_seq_length=128, sos_token=1, eos_token=2):\n",
    "    \"\"\"data: BxCxHxW\"\"\"\n",
    "    cnn_session, encoder_session, decoder_session = session\n",
    "    \n",
    "    # create cnn input\n",
    "    cnn_input = {cnn_session.get_inputs()[0].name: img}\n",
    "    src = cnn_session.run(None, cnn_input)\n",
    "    \n",
    "    # create encoder input\n",
    "    encoder_input = {encoder_session.get_inputs()[0].name: src[0]}\n",
    "    encoder_outputs, hidden = encoder_session.run(None, encoder_input)\n",
    "    translated_sentence = [[sos_token] * len(img)]\n",
    "    max_length = 0\n",
    "\n",
    "    while max_length <= max_seq_length and not all(\n",
    "        np.any(np.asarray(translated_sentence).T == eos_token, axis=1)\n",
    "    ):\n",
    "        tgt_inp = translated_sentence\n",
    "        decoder_input = {decoder_session.get_inputs()[0].name: tgt_inp[-1], decoder_session.get_inputs()[1].name: hidden, decoder_session.get_inputs()[2].name: encoder_outputs}\n",
    "\n",
    "        output, hidden, _ = decoder_session.run(None, decoder_input)\n",
    "        output = np.expand_dims(output, axis=1)\n",
    "        output = torch.Tensor(output)\n",
    "\n",
    "        values, indices = torch.topk(output, 1)\n",
    "        indices = indices[:, -1, 0]\n",
    "        indices = indices.tolist()\n",
    "\n",
    "        translated_sentence.append(indices)\n",
    "        max_length += 1\n",
    "\n",
    "        del output\n",
    "\n",
    "    translated_sentence = np.asarray(translated_sentence).T\n",
    "\n",
    "    return translated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values are same: True\n",
      "Indices are same: True\n"
     ]
    }
   ],
   "source": [
    "def topk(array, k, axis=-1, sorted=True):\n",
    "    # Use np.argpartition is faster than np.argsort, but do not return the values in order\n",
    "    # We use array.take because you can specify the axis\n",
    "    partitioned_ind = (\n",
    "        np.argpartition(array, -k, axis=axis)\n",
    "        .take(indices=range(-k, 0), axis=axis)\n",
    "    )\n",
    "    # We use the newly selected indices to find the score of the top-k values\n",
    "    partitioned_scores = np.take_along_axis(array, partitioned_ind, axis=axis)\n",
    "    \n",
    "    if sorted:\n",
    "        # Since our top-k indices are not correctly ordered, we can sort them with argsort\n",
    "        # only if sorted=True (otherwise we keep it in an arbitrary order)\n",
    "        sorted_trunc_ind = np.flip(\n",
    "            np.argsort(partitioned_scores, axis=axis), axis=axis\n",
    "        )\n",
    "        \n",
    "        # We again use np.take_along_axis as we have an array of indices that we use to\n",
    "        # decide which values to select\n",
    "        ind = np.take_along_axis(partitioned_ind, sorted_trunc_ind, axis=axis)\n",
    "        scores = np.take_along_axis(partitioned_scores, sorted_trunc_ind, axis=axis)\n",
    "    else:\n",
    "        ind = partitioned_ind\n",
    "        scores = partitioned_scores\n",
    "    \n",
    "    return scores, ind\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "x = np.random.randn(50, 50, 10, 10)\n",
    "\n",
    "axis = 2  # Change this to any axis and it'll be fine\n",
    "\n",
    "val_np, ind_np = topk(x, k=10, axis=axis)\n",
    "\n",
    "val_pt, ind_pt = torch.topk(torch.tensor(x), k=10, dim=axis)\n",
    "\n",
    "print(\"Values are same:\", np.all(val_np == val_pt.numpy()))\n",
    "print(\"Indices are same:\", np.all(ind_np == ind_pt.numpy()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
